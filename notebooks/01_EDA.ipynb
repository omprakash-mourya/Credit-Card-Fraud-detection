{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "366e4a63",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection - Exploratory Data Analysis\n",
    "\n",
    "This notebook performs comprehensive EDA on the credit card fraud dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82654c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from src.data_utils import load_data, basic_eda, get_feature_info\n",
    "from src.config import SEED\n",
    "from src.utils import set_seed\n",
    "\n",
    "# Set style and seed\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "set_seed(SEED)\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188bf5de",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Basic Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec459a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "try:\n",
    "    df = load_data()\n",
    "    print(f\"Data loaded successfully: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Dataset not found. Please download creditcard.csv from Kaggle and place it in data/creditcard.csv\")\n",
    "    print(\"Download link: https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c113431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic dataset information\n",
    "if 'df' in locals():\n",
    "    print(\"Dataset Info:\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    print(f\"Data types: {df.dtypes.value_counts()}\")\n",
    "    print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    # Display first few rows\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41451bd",
   "metadata": {},
   "source": [
    "## 2. Class Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdf64da",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df' in locals():\n",
    "    # Basic EDA\n",
    "    eda_results = basic_eda(df)\n",
    "    \n",
    "    print(\"Class Distribution:\")\n",
    "    for class_label, count in eda_results['class_counts'].items():\n",
    "        percentage = count / eda_results['total_samples'] * 100\n",
    "        label = 'Normal' if class_label == 0 else 'Fraud'\n",
    "        print(f\"  {label}: {count:,} ({percentage:.2f}%)\")\n",
    "    \n",
    "    print(f\"\\nImbalance Ratio: {eda_results['class_counts'][0] / eda_results['class_counts'][1]:.1f}:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d2e17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df' in locals():\n",
    "    # Visualize class distribution\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Count plot\n",
    "    class_counts = df['Class'].value_counts()\n",
    "    ax1.bar(['Normal', 'Fraud'], class_counts.values, color=['lightblue', 'lightcoral'])\n",
    "    ax1.set_ylabel('Count')\n",
    "    ax1.set_title('Class Distribution (Count)')\n",
    "    ax1.set_yscale('log')\n",
    "    \n",
    "    # Add count labels\n",
    "    for i, v in enumerate(class_counts.values):\n",
    "        ax1.text(i, v, f'{v:,}', ha='center', va='bottom')\n",
    "    \n",
    "    # Pie chart\n",
    "    labels = ['Normal (99.83%)', 'Fraud (0.17%)']\n",
    "    sizes = class_counts.values\n",
    "    colors = ['lightblue', 'lightcoral']\n",
    "    ax2.pie(sizes, labels=labels, colors=colors, autopct='%1.2f%%', startangle=90)\n",
    "    ax2.set_title('Class Distribution (Percentage)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dbedaf",
   "metadata": {},
   "source": [
    "## 3. Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c53ffb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df' in locals():\n",
    "    # Missing values\n",
    "    missing_values = df.isnull().sum()\n",
    "    print(f\"Missing values: {missing_values.sum()}\")\n",
    "    \n",
    "    # Descriptive statistics\n",
    "    print(\"\\nDescriptive Statistics:\")\n",
    "    display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caedaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df' in locals():\n",
    "    # Time analysis\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Time distribution\n",
    "    ax1.hist(df['Time'], bins=50, alpha=0.7, edgecolor='black')\n",
    "    ax1.set_xlabel('Time (seconds)')\n",
    "    ax1.set_ylabel('Frequency')\n",
    "    ax1.set_title('Distribution of Transaction Times')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Time by class\n",
    "    for class_val in [0, 1]:\n",
    "        subset = df[df['Class'] == class_val]['Time']\n",
    "        label = 'Normal' if class_val == 0 else 'Fraud'\n",
    "        ax2.hist(subset, bins=50, alpha=0.7, label=label, density=True)\n",
    "    \n",
    "    ax2.set_xlabel('Time (seconds)')\n",
    "    ax2.set_ylabel('Density')\n",
    "    ax2.set_title('Time Distribution by Class')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50a29c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df' in locals():\n",
    "    # Amount analysis\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Amount distribution (log scale)\n",
    "    ax1.hist(df['Amount'], bins=50, alpha=0.7, edgecolor='black')\n",
    "    ax1.set_xlabel('Amount')\n",
    "    ax1.set_ylabel('Frequency')\n",
    "    ax1.set_title('Distribution of Transaction Amounts')\n",
    "    ax1.set_yscale('log')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Amount by class (log scale)\n",
    "    for class_val in [0, 1]:\n",
    "        subset = df[df['Class'] == class_val]['Amount']\n",
    "        label = 'Normal' if class_val == 0 else 'Fraud'\n",
    "        ax2.hist(subset, bins=50, alpha=0.7, label=label, density=True)\n",
    "    \n",
    "    ax2.set_xlabel('Amount')\n",
    "    ax2.set_ylabel('Density')\n",
    "    ax2.set_title('Amount Distribution by Class')\n",
    "    ax2.legend()\n",
    "    ax2.set_yscale('log')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Box plot\n",
    "    df_sample = df.sample(n=10000, random_state=SEED)  # Sample for better visualization\n",
    "    sns.boxplot(data=df_sample, x='Class', y='Amount', ax=ax3)\n",
    "    ax3.set_title('Amount Distribution by Class (Boxplot)')\n",
    "    ax3.set_yscale('log')\n",
    "    \n",
    "    # Statistics\n",
    "    amount_stats = df.groupby('Class')['Amount'].describe()\n",
    "    amount_stats.plot(kind='bar', ax=ax4)\n",
    "    ax4.set_title('Amount Statistics by Class')\n",
    "    ax4.set_xlabel('Statistic')\n",
    "    ax4.set_ylabel('Amount')\n",
    "    ax4.legend(['Normal', 'Fraud'])\n",
    "    ax4.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Amount Statistics by Class:\")\n",
    "    display(amount_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2842bac7",
   "metadata": {},
   "source": [
    "## 4. PCA Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98366b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df' in locals():\n",
    "    # Analyze V features\n",
    "    v_features = [col for col in df.columns if col.startswith('V')]\n",
    "    \n",
    "    # Correlation with target\n",
    "    correlations = df[v_features + ['Class']].corr()['Class'].drop('Class').sort_values(key=abs, ascending=False)\n",
    "    \n",
    "    # Plot top correlated features\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Correlation plot\n",
    "    top_features = correlations.head(10)\n",
    "    colors = ['red' if x < 0 else 'blue' for x in top_features.values]\n",
    "    ax1.barh(range(len(top_features)), top_features.values, color=colors, alpha=0.7)\n",
    "    ax1.set_yticks(range(len(top_features)))\n",
    "    ax1.set_yticklabels(top_features.index)\n",
    "    ax1.set_xlabel('Correlation with Class')\n",
    "    ax1.set_title('Top 10 Features Correlated with Fraud')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Feature distributions for top correlated feature\n",
    "    top_feature = abs(correlations).idxmax()\n",
    "    for class_val in [0, 1]:\n",
    "        subset = df[df['Class'] == class_val][top_feature]\n",
    "        label = 'Normal' if class_val == 0 else 'Fraud'\n",
    "        ax2.hist(subset, bins=50, alpha=0.7, label=label, density=True)\n",
    "    \n",
    "    ax2.set_xlabel(top_feature)\n",
    "    ax2.set_ylabel('Density')\n",
    "    ax2.set_title(f'Distribution of {top_feature} by Class')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Most correlated feature with fraud: {top_feature} (r = {correlations[top_feature]:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decd95e2",
   "metadata": {},
   "source": [
    "## 5. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102955d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df' in locals():\n",
    "    # Correlation matrix for selected features\n",
    "    features_to_plot = ['Time', 'Amount'] + [f'V{i}' for i in range(1, 11)] + ['Class']\n",
    "    corr_matrix = df[features_to_plot].corr()\n",
    "    \n",
    "    # Plot correlation matrix\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "    sns.heatmap(corr_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,\n",
    "                square=True, linewidths=0.5, cbar_kws={\"shrink\": .8}, fmt='.2f')\n",
    "    plt.title('Correlation Matrix (Selected Features)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d46e7c",
   "metadata": {},
   "source": [
    "## 6. Dimensionality Reduction Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1697a2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df' in locals():\n",
    "    # Sample data for visualization (t-SNE is computationally expensive)\n",
    "    sample_size = 5000\n",
    "    df_sample = df.sample(n=sample_size, random_state=SEED)\n",
    "    \n",
    "    # Prepare features (exclude Class)\n",
    "    X_sample = df_sample.drop('Class', axis=1)\n",
    "    y_sample = df_sample['Class']\n",
    "    \n",
    "    print(f\"Performing dimensionality reduction on {sample_size} samples...\")\n",
    "    \n",
    "    # PCA\n",
    "    pca = PCA(n_components=2, random_state=SEED)\n",
    "    X_pca = pca.fit_transform(X_sample)\n",
    "    \n",
    "    # t-SNE (this may take a while)\n",
    "    print(\"Computing t-SNE... This may take a few minutes.\")\n",
    "    tsne = TSNE(n_components=2, random_state=SEED, perplexity=30, n_iter=1000)\n",
    "    X_tsne = tsne.fit_transform(X_sample)\n",
    "    \n",
    "    # Plot results\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # PCA plot\n",
    "    scatter1 = ax1.scatter(X_pca[:, 0], X_pca[:, 1], c=y_sample, cmap='coolwarm', alpha=0.6, s=1)\n",
    "    ax1.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
    "    ax1.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
    "    ax1.set_title('PCA Visualization')\n",
    "    plt.colorbar(scatter1, ax=ax1, label='Class')\n",
    "    \n",
    "    # t-SNE plot\n",
    "    scatter2 = ax2.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y_sample, cmap='coolwarm', alpha=0.6, s=1)\n",
    "    ax2.set_xlabel('t-SNE 1')\n",
    "    ax2.set_ylabel('t-SNE 2')\n",
    "    ax2.set_title('t-SNE Visualization')\n",
    "    plt.colorbar(scatter2, ax=ax2, label='Class')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"PCA explained variance: {pca.explained_variance_ratio_.sum():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7276665",
   "metadata": {},
   "source": [
    "## 7. Time-based Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0957edbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df' in locals():\n",
    "    # Convert time to hours\n",
    "    df_time = df.copy()\n",
    "    df_time['Hour'] = (df_time['Time'] / 3600) % 24\n",
    "    \n",
    "    # Fraud rate by hour\n",
    "    hourly_fraud = df_time.groupby(df_time['Hour'].astype(int)).agg({\n",
    "        'Class': ['count', 'sum', 'mean']\n",
    "    }).round(4)\n",
    "    \n",
    "    hourly_fraud.columns = ['Total_Transactions', 'Fraud_Count', 'Fraud_Rate']\n",
    "    \n",
    "    # Plot time-based patterns\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10))\n",
    "    \n",
    "    # Transactions by hour\n",
    "    ax1.bar(hourly_fraud.index, hourly_fraud['Total_Transactions'], alpha=0.7)\n",
    "    ax1.set_xlabel('Hour of Day')\n",
    "    ax1.set_ylabel('Number of Transactions')\n",
    "    ax1.set_title('Transaction Volume by Hour')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Fraud rate by hour\n",
    "    ax2.bar(hourly_fraud.index, hourly_fraud['Fraud_Rate'], color='red', alpha=0.7)\n",
    "    ax2.set_xlabel('Hour of Day')\n",
    "    ax2.set_ylabel('Fraud Rate')\n",
    "    ax2.set_title('Fraud Rate by Hour')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Hourly Statistics:\")\n",
    "    display(hourly_fraud.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cc5f52",
   "metadata": {},
   "source": [
    "## 8. Summary and Key Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a928f3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df' in locals():\n",
    "    print(\"=\" * 60)\n",
    "    print(\"EXPLORATORY DATA ANALYSIS SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(f\"\\n📊 Dataset Overview:\")\n",
    "    print(f\"   • Total transactions: {len(df):,}\")\n",
    "    print(f\"   • Features: {len(df.columns) - 1}\")\n",
    "    print(f\"   • Missing values: {df.isnull().sum().sum()}\")\n",
    "    \n",
    "    print(f\"\\n🎯 Class Distribution:\")\n",
    "    class_counts = df['Class'].value_counts()\n",
    "    print(f\"   • Normal transactions: {class_counts[0]:,} ({class_counts[0]/len(df):.2%})\")\n",
    "    print(f\"   • Fraud transactions: {class_counts[1]:,} ({class_counts[1]/len(df):.2%})\")\n",
    "    print(f\"   • Imbalance ratio: {class_counts[0]/class_counts[1]:.0f}:1\")\n",
    "    \n",
    "    print(f\"\\n💰 Transaction Amounts:\")\n",
    "    print(f\"   • Normal transactions median: ${df[df['Class']==0]['Amount'].median():.2f}\")\n",
    "    print(f\"   • Fraud transactions median: ${df[df['Class']==1]['Amount'].median():.2f}\")\n",
    "    print(f\"   • Max amount: ${df['Amount'].max():.2f}\")\n",
    "    \n",
    "    print(f\"\\n🔍 Key Correlations:\")\n",
    "    v_features = [col for col in df.columns if col.startswith('V')]\n",
    "    correlations = df[v_features + ['Class']].corr()['Class'].drop('Class')\n",
    "    top_positive = correlations.nlargest(3)\n",
    "    top_negative = correlations.nsmallest(3)\n",
    "    \n",
    "    print(f\"   • Strongest positive correlations:\")\n",
    "    for feature, corr in top_positive.items():\n",
    "        print(f\"     - {feature}: {corr:.3f}\")\n",
    "    \n",
    "    print(f\"   • Strongest negative correlations:\")\n",
    "    for feature, corr in top_negative.items():\n",
    "        print(f\"     - {feature}: {corr:.3f}\")\n",
    "    \n",
    "    print(f\"\\n📈 Modeling Considerations:\")\n",
    "    print(f\"   • Highly imbalanced dataset - consider SMOTE/class weights\")\n",
    "    print(f\"   • PCA features suggest complex patterns\")\n",
    "    print(f\"   • Time and amount show different distributions by class\")\n",
    "    print(f\"   • No missing values - clean dataset\")\n",
    "    print(f\"   • Focus on recall (catching fraud) over precision\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "else:\n",
    "    print(\"Dataset not loaded. Please ensure creditcard.csv is in the data/ directory.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
